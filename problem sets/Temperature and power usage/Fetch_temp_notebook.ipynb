{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a17fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "\n",
    "#configure webdrive not to open windows\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "TEMP_PATH = os.path.join('datasets', 'temperatures')\n",
    "\n",
    "\n",
    "def fetch_daily_temp(page, date, temp_path=TEMP_PATH):\n",
    "    '''Get daily temperatures from wunderground'''\n",
    "    \n",
    "    #configure webdrive not to open windows\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('headless')\n",
    "    \n",
    "    #initialize driver\n",
    "    # Change argument to the location you installed the chrome driver\n",
    "    driver = webdriver.Chrome(r'C:\\Users\\rab53\\OneDrive\\Desktop\\Python\\chromedriver.exe', options=chrome_options)\n",
    "    \n",
    "    #add requested date to wunderground url\n",
    "    URL = str(page) + str(date)\n",
    "    driver.get(URL)\n",
    "    time.sleep(4)\n",
    "    r = driver.page_source\n",
    "    driver.quit()\n",
    "    \n",
    "    #parse webpage\n",
    "    soup = BS(r, 'html.parser')\n",
    "    container = soup.find('lib-city-history-observation')\n",
    "    check = container.find('tbody')\n",
    "    \n",
    "    #use pandas to get table\n",
    "    try:\n",
    "        df = pd.read_html(str(container))[0]\n",
    "    except ValueError:\n",
    "        bad_dates.append(date)\n",
    "        \n",
    "    if not os.path.isdir(temp_path):\n",
    "        os.makedirs(temp_path)\n",
    "        \n",
    "    df.to_csv(os.path.join(temp_path, f'{date}.csv'))\n",
    "    \n",
    "    #pause again to prevent making too many requestions, robots.txt -> 3 seconds\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0425e2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['2022-01-13', '2022-01-14', '2022-01-15', '2022-01-16',\n",
       "             '2022-01-17', '2022-01-18', '2022-01-19', '2022-01-20',\n",
       "             '2022-01-21', '2022-01-22', '2022-01-23', '2022-01-24',\n",
       "             '2022-01-25', '2022-01-26', '2022-01-27', '2022-01-28',\n",
       "             '2022-01-29', '2022-01-30', '2022-01-31', '2022-02-01'],\n",
       "            dtype='period[D]', freq='D')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_to_fetch = pd.period_range(start='1-13-2022', end='2-01-2022', freq='D')\n",
    "dates_to_fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b06ad4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_page = 'https://www.wunderground.com/history/daily/us/tx/austin/KAUS/date/'\n",
    "\n",
    "for i in dates_to_fetch:\n",
    "    fetch_daily_temp(web_page, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
